{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Place in the cell below the code to collect all the data from vcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Embedding, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model, Sequential\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import keras_metrics\n",
    "def recall(y_true, y_pred):\t\n",
    "    \"\"\"Recall metric.\t\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\t\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\t\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\t\n",
    "    \"\"\"Precision metric.\t\n",
    "    Only computes a batch-wise average of precision. Computes the precision, a\n",
    "    metric for multi-label classification of how many selected items are\n",
    "    relevant.\n",
    "    \"\"\"\t\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\t\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\t\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\t\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Computes the F1 Score\n",
    "    Only computes a batch-wise average of recall. Computes the recall, a metric\n",
    "    for multi-label classification of how many relevant items are selected.\t\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters setup\n",
    "There are 2607 medical records as of now. Their length is variable, the longest is 3931 words long. On average they are 801  words long. More than 98% of them is shorter than 2000 words.\n",
    "We have a word2vec dictionary of 27610 entries with 256 features each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_samples = 2607\n",
    "maxlen = 1000 #cutoff for medical record's length\n",
    "training_samples = int(0.7 * total_samples ) #split the dataset as you wish\n",
    "validation_samples = int(0.15 * total_samples )\n",
    "test_samples = total_samples-training_samples-validation_samples\n",
    "max_words = 7000 #how many words to take into account "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming data fetched from the database\n",
    "data = x_rep_raw\n",
    "del x_rep_raw\n",
    "labels = y_rep \n",
    "del y_rep\n",
    "#########################################################################################################################\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen) #Pads sequences to the same length.\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]\n",
    "x_test = data[total_samples-test_samples:total_samples]\n",
    "y_test = labels[total_samples-test_samples:total_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing and preparing the word2vec word-embeddings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_dir = '/home/v_charvet/workspace/data'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(w2v_dir, 'w2v_reports_256.vec'), encoding='utf-8',errors='ignore')\n",
    "dummy = f.readline() #to skip the first line that tells: n.of words n.of features\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#Preparing the GloVe word-embeddings matrix\n",
    "embedding_dim = 256 #number of , #we've got the 128 features option too\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Replace the next cell with any of the models uploaded and make some adjustments on the output file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Bidirectional(layers.GRU(32))) #32, 64, 100 would be best\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.layers[0].set_weights([embedding_matrix]) \n",
    "model.layers[0].trainable = False #to use pretrained embeddings\n",
    "\n",
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01) #Optimizer\n",
    "\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=[recall])\n",
    "history = model.fit(x_train, y_train,epochs=10,batch_size=64,validation_data=(x_val, y_val)) \n",
    "\n",
    "#optional:\n",
    "#model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec = history.history['recall']\n",
    "val_rec = history.history['val_recall']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, rec, 'bo', label='Training rec')\n",
    "plt.plot(epochs, val_rec, 'b', label='Validation rec')\n",
    "plt.title('Training and validation rec')\n",
    "plt.savefig('DITEP_modelname_rec.png') #Choose output image name\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('DITEP_modelname_loss.png') #Choose output image name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Customize what you want to retain of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test recall', scores[1])\n",
    "scores.extend(['val_rec:'])\n",
    "scores.extend(val_acc)\n",
    "f=open('out_DITEP_modelname.txt','w') #Choose output .txt name\n",
    "temp=''\n",
    "for i in scores:\n",
    "    temp+=str(i)\n",
    "    temp+='\\n'\n",
    "f.write(temp)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
